{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziGdeb7w-lY4"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iPgS20VDA4m8",
        "outputId": "6393c686-d068-41a1-d519-8f1ff626b3b2"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install torch torchvision\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gKgRInWlrt5"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr_Su9-YlbGP"
      },
      "source": [
        "# Siamese Algorithm for Image Comparision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wK5mOAdjl2Sk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-rsy3ar9l4MQ"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Preprocessing for input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uwhWnpRkl6B_"
      },
      "outputs": [],
      "source": [
        "# CNN-based feature extractor (pretrained model)\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        # Remove the last fully connected layer to get features\n",
        "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3gqUa-CBl79L"
      },
      "outputs": [],
      "source": [
        "# Siamese Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "\n",
        "    def forward(self, image1, image2):\n",
        "        # Extract features from both images\n",
        "        feature1 = self.feature_extractor(image1)\n",
        "        feature2 = self.feature_extractor(image2)\n",
        "\n",
        "        # Flatten the feature maps\n",
        "        feature1 = feature1.view(feature1.size(0), -1)\n",
        "        feature2 = feature2.view(feature2.size(0), -1)\n",
        "\n",
        "        # Calculate similarity (e.g., cosine similarity)\n",
        "        similarity = F.cosine_similarity(feature1, feature2)\n",
        "        return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "XDS8PeYHl94Q"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = SiameseNetwork().to(device)\n",
        "model.eval()\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "    return image.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "9ffTwJXZl_q5"
      },
      "outputs": [],
      "source": [
        "# Function to compute similarity score between two images\n",
        "def compute_similarity(image_path1, image_path2):\n",
        "    image1 = load_image(image_path1)\n",
        "    image2 = load_image(image_path2)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        similarity_score = model(image1, image2)\n",
        "\n",
        "    return similarity_score.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca9trrK5k3SE",
        "outputId": "1591f77f-74f8-4e06-950b-9333b117e87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity Score: 0.6734\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "similarity_score = compute_similarity('/content/!image.jpg', '/content/Venkata-Sai-Bhaskar-Image.jpg')\n",
        "print(f'Similarity Score: {similarity_score:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
